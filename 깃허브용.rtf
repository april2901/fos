{\rtf1\ansi\ansicpg949\cocoartf2822
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\froman\fcharset0 Times-Roman;\f1\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red0\green0\blue233;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c0\c0\c93333;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid101\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid201\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid3}
{\list\listtemplateid4\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid301\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid4}
{\list\listtemplateid5\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat3\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid401\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid5}
{\list\listtemplateid6\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat4\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid501\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid6}
{\list\listtemplateid7\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat5\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid601\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid7}
{\list\listtemplateid8\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat6\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid701\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid8}
{\list\listtemplateid9\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat7\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid801\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid9}
{\list\listtemplateid10\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat8\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid901\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid10}
{\list\listtemplateid11\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat9\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1001\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid11}
{\list\listtemplateid12\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat10\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1101\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid12}
{\list\listtemplateid13\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat11\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1201\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid13}
{\list\listtemplateid14\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat12\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1301\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid14}
{\list\listtemplateid15\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1401\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid15}
{\list\listtemplateid16\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1501\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid16}
{\list\listtemplateid17\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1601\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid17}
{\list\listtemplateid18\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1701\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid18}
{\list\listtemplateid19\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1801\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid19}
{\list\listtemplateid20\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1901\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid20}
{\list\listtemplateid21\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat3\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2001\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid21}
{\list\listtemplateid22\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2101\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid22}
{\list\listtemplateid23\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat4\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2201\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid23}
{\list\listtemplateid24\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2301\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid24}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}{\listoverride\listid4\listoverridecount0\ls4}{\listoverride\listid5\listoverridecount0\ls5}{\listoverride\listid6\listoverridecount0\ls6}{\listoverride\listid7\listoverridecount0\ls7}{\listoverride\listid8\listoverridecount0\ls8}{\listoverride\listid9\listoverridecount0\ls9}{\listoverride\listid10\listoverridecount0\ls10}{\listoverride\listid11\listoverridecount0\ls11}{\listoverride\listid12\listoverridecount0\ls12}{\listoverride\listid13\listoverridecount0\ls13}{\listoverride\listid14\listoverridecount0\ls14}{\listoverride\listid15\listoverridecount0\ls15}{\listoverride\listid16\listoverridecount0\ls16}{\listoverride\listid17\listoverridecount0\ls17}{\listoverride\listid18\listoverridecount0\ls18}{\listoverride\listid19\listoverridecount0\ls19}{\listoverride\listid20\listoverridecount0\ls20}{\listoverride\listid21\listoverridecount0\ls21}{\listoverride\listid22\listoverridecount0\ls22}{\listoverride\listid23\listoverridecount0\ls23}{\listoverride\listid24\listoverridecount0\ls24}}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sa240\partightenfactor0

\f0\fs24 \cf0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 FoS(Focus on Speaking)\uc0\u8232 Group 12\u8232 {\field{\*\fldinst{HYPERLINK "https://github.com/april2901/ai-assistant-for-presentation"}}{\fldrslt \cf3 \ul \ulc3 \strokec3 https://github.com/april2901/ai-assistant-for-presentation}}\
Sangyoon Kwon\uc0\u8232 Department of Computer Science\u8232 Backend Development\u8232 Seoul, Republic of Korea\u8232 {\field{\*\fldinst{HYPERLINK "mailto:is0110@hanyang.ac.kr"}}{\fldrslt \cf3 \ul \ulc3 \strokec3 is0110@hanyang.ac.kr}}\
Hyeyun Kwon\uc0\u8232 Department of Information Systems\u8232 Frontend Development\u8232 Seoul, Republic of Korea\u8232 {\field{\*\fldinst{HYPERLINK "mailto:herakwon1124@hanyang.ac.kr"}}{\fldrslt \cf3 \ul \ulc3 \strokec3 herakwon1124@hanyang.ac.kr}}\
Dohoon Kim\uc0\u8232 Department of Computer Science\u8232 Backend Development\u8232 Seoul, Republic of Korea\u8232 {\field{\*\fldinst{HYPERLINK "mailto:april2901@hanyang.ac.kr"}}{\fldrslt \cf3 \ul \ulc3 \strokec3 april2901@hanyang.ac.kr}}\
Seohyun Kim\uc0\u8232 Department of Information Systems\u8232 Frontend Development\u8232 Seoul, Republic of Korea\u8232 {\field{\*\fldinst{HYPERLINK "mailto:dianwls0326@hanyang.ac.kr"}}{\fldrslt \cf3 \ul \ulc3 \strokec3 dianwls0326@hanyang.ac.kr}}\
Daeun Lee\uc0\u8232 Division of Business Administration\u8232 UI Design, PM\u8232 Seoul, Republic of Korea\u8232 {\field{\*\fldinst{HYPERLINK "mailto:shinran2929@hanyang.ac.kr"}}{\fldrslt \cf3 \ul \ulc3 \strokec3 shinran2929@hanyang.ac.kr}}\
Minhyuk Jang\uc0\u8232 Division of Business Administration\u8232 UI Design, PM\u8232 Seoul, Republic of Korea\u8232 {\field{\*\fldinst{HYPERLINK "mailto:jmh12230@hanyang.ac.kr"}}{\fldrslt \cf3 \ul \ulc3 \strokec3 jmh12230@hanyang.ac.kr}}\
Abstract\'97 In modern business and educational environments, meetings and presentations are key means of communication, and their importance continues to grow. However, presenters and participants often experience cognitive overload as they manage speech delivery, script reference, slide transitions, and time management while also trying to follow complex discussion flows and decisions. This leads to topic drift, loss of focus, and unclear outcomes. To address these issues, this project proposes an LG display\'96linked real-time meeting AI prompter that extends a traditional teleprompter into an active, context-aware assistant. The system listens to participants\'92 speech, interprets the meeting context in real time, and presents the next required information\'97such as agenda structure, current topic, decisions, and action items\'97on LG displays, while providing a private coaching dashboard for the presenter or host. Core features include real-time STT, flexible speech-to-script matching, keyword omission detection, a real-time feedback dashboard, agenda visualization, decision and action-item extraction, and fact-check widgets. A Meeting Summary Report summarizes key topics, ideas, decisions, and action items after the session. Through these functions, the project aims to improve both individual presentation quality and overall meeting efficiency, and to explore integration within LG\'92s smart office ecosystem.\
Keywords\'97 Speech Recognition, Real-Time STT, Script Synchronization, Real-Time Teleprompter, Slide Automation, Agenda Tracking, Presentation Feedback, Human-Computer Interaction, Meeting Intelligence\
Role Assignment -\uc0\u8232 Roles / Name / Task description and etc.\
User\uc0\u8232 Daeun Lee, Minhyuk Jang\u8232 Tests the prototype from the user\'92s perspective, focusing on interface usability, speech synchronization accuracy, and overall user experience. Provides qualitative feedback for refinement.\
Customer (Assumed Client)\uc0\u8232 LG Electronics\u8232 Defines requirements for smart office presentation support software and evaluates its feasibility for integration with LG\'92s webOS-based business ecosystem.\
Software Developer\uc0\u8232 Sangyoon Kwon, Dohoon Kim (Backend),\u8232 Hyeyun Kwon, Seohyun Kim (Frontend)\u8232 Responsible for system implementation including backend server logic, database management, API communication, and frontend interface development. Ensures real-time synchronization and stable slide automation.\
Development Manager & UI Designer\uc0\u8232 Daeun Lee, Minhyuk Jang\u8232 Oversees project planning, documentation, and communication between development teams. Manages task allocation, schedule tracking, design of interface and quality assurance.\
I. INTRODUCTION\
A. Challenges in Modern Presentations and Meetings\uc0\u8232 In professional and academic settings, presentations and meetings have become essential tools for sharing ideas and making decisions. Yet presenters and facilitators must simultaneously handle speech delivery, script reference, slide transitions, and time tracking, while participants struggle to follow complex discussion flows and remember key points. This often causes interruptions in the presentation flow, omission of important content, topic drift during discussions, and unclear conclusions, ultimately reducing communication efficiency.\
B. Limitations of Existing Solutions\uc0\u8232 Existing tools such as teleprompters, timers, and subtitle features mainly provide static information or simple transcription. They are useful for displaying text but do not actively intervene in real time to prevent topic drift or support decision alignment. Many AI-based meeting services focus on post-meeting summaries or minutes, which help review what happened but do not improve the efficiency of the meeting while it is in progress. As a result, core issues such as cognitive overload and live meeting inefficiency remain unresolved.\
C. Project Goals and Proposed Solution\uc0\u8232 This project proposes an integrated support system that covers preparation, live delivery, and post-meeting feedback. The core concept is an \'93LG Display\'96Linked Real-Time Meeting AI Prompter.\'94 The system continuously listens to meeting audio, analyzes the semantic context of each utterance, and surfaces what the meeting needs next: agenda structure, current topic, decisions, action items, and fact-check results. At the same time, it provides a private teleprompter and coaching dashboard for the presenter or host, helping with script tracking, omission alerts, pacing, and gesture suggestions. The ultimate goal is to reduce cognitive load and improve meeting focus and decision-making speed.\
D. Dual-Screen Architecture for LG Displays\uc0\u8232 To support both individual coaching and shared awareness, the system adopts a dual-screen architecture. Screen 1 (Presenter Dashboard) is shown on the presenter\'92s personal device (e.g., LG Gram) and provides a private teleprompter, omission alerts, pace metrics, and AI suggestions. Screen 2 (Shared Meeting Board) is shown on LG signage, LG One:Quick, or conference room TVs and visualizes slides, the real-time agenda map, decisions and action items, and fact-check widgets for all participants. This separation allows the presenter to receive rich guidance without overwhelming the audience, while participants share a clear view of where the meeting is and what has been decided.\
II. REQUIREMENTS\
A. Before Presentation\uc0\u8232 This phase focuses on the preparation process before a presenter begins their presentation. Users interact with the system to upload materials, create a script, and adjust content to fit the presentation environment.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls1\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Slide-Script Alignment Recognition and Consulting\uc0\u8232 When a user uploads a PPTX or PDF file, the system extracts textual and visual elements using python-pptx and the Google Vision API (OCR). A multimodal LLM processes these elements to interpret textual and graphical contexts, generating a coherent draft script for each slide.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 Acceptance Criteria\uc0\u8232 \'95 OCR text recognition accuracy \u8805  95%\u8232 \'95 Draft script grammatical accuracy \u8805  95%\u8232 \'95 Slide\'96text coherence \u8805  95%\
Input & Output\uc0\u8232 \'95 Input: Presentation file (.pptx, .pdf)\u8232 \'95 Output: Structured text/image metadata, draft script (3\'966 sentences per slide)\
Constraints\uc0\u8232 \'95 Max 100 slides\u8232 \'95 Max file size 200 MB\u8232 \'95 Max 10 images per slide\u8232 \'95 Supported formats: PPTX, PDF\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls2\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Presentation Environment-Specific Script Adjustment\uc0\u8232 The system adjusts the script\'92s vocabulary level, tone, and length based on the audience type (non-expert / practitioner / expert), target presentation time, and speaker\'92s pace. Using TensorFlow.js-based vision models, audience facial expressions are analyzed every 3 seconds to compute a \'93focus score\'94 (0\'96100). When time is running short or audience engagement decreases, an LLM provides real-time summaries or interactive remarks.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 Acceptance Criteria\uc0\u8232 \'95 Script adjustment time \u8804  5 s\u8232 \'95 Focus detection accuracy \u8805  85%\u8232 \'95 Timing deviation \u8804  \'b15%\u8232 \'95 Script fluency \u8805  90%\
Input & Output\uc0\u8232 \'95 Input: Audience type, target duration, speech rate (WPM), tone, audience video data\u8232 \'95 Output: Adjusted script (.txt), recommended timing table, real-time teleprompter feedback\
Constraints\uc0\u8232 \'95 Camera \u8805  720p\u8232 \'95 Max 10 audience members detectable\u8232 \'95 LLM request frequency \u8804  1 per 10 s\u8232 \'95 Presentation \u8804  60 min\
B. Live Delivery Phase\uc0\u8232 This phase involves real-time interaction between the user and the system during the actual presentation. The system detects the presenter's speech and performs instant support tasks like synchronization, feedback, and suggestions.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls3\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Real-time Teleprompter (Meeting Mode Support)\uc0\u8232 The system transcribes the presenter\'92s and participants\'92 speech in real time using Google Cloud or Naver Clova STT and aligns it with the prepared script via KoSentence-BERT semantic similarity. The current sentence is visually highlighted on the teleprompter. In meeting mode, the STT pipeline can capture speech from multiple people in the room as a single mixed audio stream; downstream modules operate on this combined transcript.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 Acceptance Criteria\uc0\u8232 \'95 Speech\'96script synchronization delay \u8804  1 s\u8232 \'95 Highlight accuracy \u8805  95%\u8232 \'95 Alignment deviation \u8804  1 sentence\
Input & Output\uc0\u8232 \'95 Input: Microphone audio (.wav, .mp3, \u8805  16 kHz), script file (.txt)\u8232 \'95 Output: Real-time highlighted script text and STT logs\
Constraints\uc0\u8232 \'95 Session length \u8804  60 min\u8232 \'95 STT throughput \u8805  50 words/s\u8232 \'95 API cost \u8776  $0.006/min\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls4\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Automatic Slide Transition\uc0\u8232 Through the Microsoft PowerPoint COM API, slides are automatically advanced when the script reaches predefined transition points.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 Acceptance Criteria\uc0\u8232 \'95 Transition latency \u8804  0.5 s\u8232 \'95 Transition accuracy \u8805  95%\u8232 \'95 Failure rate \u8804  5%\
Input & Output\uc0\u8232 \'95 Input: Slide file (.pptx), predefined transition IDs\u8232 \'95 Output: Automatically advanced slide display\
Constraints\uc0\u8232 \'95 Max 100 slides\u8232 \'95 Requires PowerPoint 2016 or later\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls5\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Flexible Speech-to-Script Matching\uc0\u8232 The system maintains synchronization even when speech deviates lexically from the script. Primary matching uses KoSentence-BERT vector similarity (threshold \u8805  0.8), followed by secondary LLM-based contextual verification if necessary.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 Acceptance Criteria\uc0\u8232 \'95 Matching success rate \u8805  90%\u8232 \'95 False match rate \u8804  5%\u8232 \'95 Matching latency \u8804  0.3 s per sentence\
Input & Output\uc0\u8232 \'95 Input: STT transcript, script text\u8232 \'95 Output: Matched sentence ID and highlight position\
Constraints\uc0\u8232 \'95 LLM call limit \u8804  1 per second\u8232 \'95 STT buffering \u8804  5 s\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls6\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Key Content Omission Detection\uc0\u8232 Detects missing predefined key phrases using cosine similarity (threshold \u8805  0.75) and alerts the presenter within 3 seconds.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 Acceptance Criteria\uc0\u8232 \'95 Detection precision \u8805  95%\u8232 \'95 False alarm \u8804  5%\u8232 \'95 Alert delay \u8804  2 s\
Input & Output\uc0\u8232 \'95 Input: STT transcript, key phrase list (\u8804  50)\u8232 \'95 Output: Omission alert and log file\
Constraints\uc0\u8232 \'95 Max 500 sentences compared\u8232 \'95 STT buffering interval: 5 s\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls7\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	5	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Real-time Script Reconstruction\uc0\u8232 When omissions are detected, missing segments are asynchronously sent to an LLM that generates supplementary sentences within 5 seconds. Approved sentences are integrated into the script in real time.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 Acceptance Criteria\uc0\u8232 \'95 Supplement generation \u8804  5 s\u8232 \'95 Contextual coherence \u8805  90%\u8232 \'95 Integration success \u8805  90%\
Input & Output\uc0\u8232 \'95 Input: Missing sentence ID, context text, LLM API key\u8232 \'95 Output: Supplementary sentence, updated script\
Constraints\uc0\u8232 \'95 Max 10 API calls per minute\u8232 \'95 Sentence length \u8804  100 characters\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls8\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	6	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Real-time Presenter Dashboard\uc0\u8232 The system visualizes metrics such as words per minute (WPM), voice volume, and progress rate using the Web Audio API, and applies TensorFlow Lite models for basic emotion recognition (e.g., tension/calmness).\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 Acceptance Criteria\uc0\u8232 \'95 Data refresh \u8804  2 s\u8232 \'95 Emotion inference error \u8804  \'b15%\u8232 \'95 Visualization accuracy \u8805  95%\
Input & Output\uc0\u8232 \'95 Input: Audio stream, STT logs\u8232 \'95 Output: Live dashboard showing progress, WPM, emotional state\
Constraints\uc0\u8232 \'95 Sampling rate \u8805  16 kHz\u8232 \'95 Dashboard latency \u8804  1 s\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls9\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	7	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Speech Gesture Suggestions\uc0\u8232 Before the presentation, the system analyzes slide images with a multimodal LLM to detect key visual elements (graphs, photos, diagrams) and map them to related keywords. During speech, when such keywords appear in STT, gesture icons (e.g., pointing, emphasis) are displayed on the teleprompter.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 Acceptance Criteria\uc0\u8232 \'95 Suggestion latency \u8804  2 s\u8232 \'95 Gesture relevance \u8805  85%\u8232 \'95 Recognition accuracy \u8805  90%\
Input & Output\uc0\u8232 \'95 Input: Slide images, script keywords\u8232 \'95 Output: Gesture icons displayed on teleprompter\
Constraints\uc0\u8232 \'95 Max 3 visual mappings per keyword\u8232 \'95 Display duration: 2\'963 s\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls10\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	8	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Real-Time Context and Intent Tagging\uc0\u8232 The system analyzes STT text in real time and classifies each utterance according to its intent and type. This information is used as the foundation for the agenda map, decision board, and fact-check triggers.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 Supported Tags\uc0\u8232 \'95 General comment\u8232 \'95 Idea proposal\u8232 \'95 Negative/Positive feedback\u8232 \'95 Decision\u8232 \'95 Request / Action Item\u8232 \'95 Question\u8232 \'95 Fact-check request\
Acceptance Criteria\uc0\u8232 \'95 All utterances receive at least one tag from the predefined set\u8232 \'95 Intent classification accuracy \u8805  85% on test samples\
Input & Output\uc0\u8232 \'95 Input: STT transcript segmented into utterances\u8232 \'95 Output: Tagged utterance stream (text + tag(s) + timestamp)\
Constraints\uc0\u8232 \'95 Classification latency \u8804  0.5 s per utterance\u8232 \'95 The tagging model must operate within the WebSocket round-trip time budget\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls11\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	9	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Real-Time Agenda Map\uc0\u8232 Using the tagged utterance stream, the system builds a real-time agenda map to prevent topic deviation and improve shared awareness. Each emerging topic is registered as a node in a network graph displayed on Screen 2.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 Acceptance Criteria\uc0\u8232 \'95 Screen 2 displays a live STT log and its mapping to agenda nodes\u8232 \'95 Utterances tagged as \'93Idea,\'94 \'93Decision,\'94 or \'93Action Item\'94 are grouped under appropriate agenda nodes\u8232 \'95 Nodes are color-coded by agenda type\u8232 \'95 The active topic is clearly highlighted\u8232 \'95 Node detail view shows STT snippet and timestamp\
Input & Output\uc0\u8232 \'95 Input: Tagged utterance stream (from Requirement 8), semantic embeddings\u8232 \'95 Output: Real-time agenda network graph on Screen 2\
Constraints\uc0\u8232 \'95 Graph update interval \u8804  2 s\u8232 \'95 Max 30 agenda nodes per session\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls12\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	10	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Dual-Screen Synchronization between Presenter and Shared Display\uc0\u8232 The system keeps Screen 1 (Presenter Dashboard) and Screen 2 synchronized while respecting privacy boundaries.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 Acceptance Criteria\uc0\u8232 \'95 Slide transition latency between Screen 1 and Screen 2 \u8804  0.5 s\u8232 \'95 No private elements (teleprompter text, omission alerts, AI suggestions) appear on Screen 2\
Input & Output\uc0\u8232 \'95 Input: Slide control events, layout state, synchronization messages\u8232 \'95 Output: Consistent view of the current slide and agenda state on Screen 2\
Constraints\uc0\u8232 \'95 WebSocket synchronization interval \u8804  1 s\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls13\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	11	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Real-time Decisions and Action Item Widget\uc0\u8232 The system captures utterances tagged as decision or action item and surfaces them in a dedicated widget on Screen 2, often placed below or beside the agenda map.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 Acceptance Criteria\uc0\u8232 \'95 Detection coverage for decision-like and action-like utterances \u8805  90% on test scenarios\u8232 \'95 New items appear in the list within 2 seconds of the utterance\
Input & Output\uc0\u8232 \'95 Input: Tagged utterance stream (Decision / Action Item tags)\u8232 \'95 Output: Real-time decision & action-item list on Screen 2\
Constraints\uc0\u8232 \'95 Max 100 items per session\u8232 \'95 Each item stored with its text content and timestamp, with a link to the original transcript segment\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls14\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	12	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Real-Time Fact-Check and Research Widget\uc0\u8232 When the system detects a Fact-check request tag, it triggers a lightweight research pipeline (RAG or web search) and surfaces the result on Screen 2.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 Acceptance Criteria\uc0\u8232 \'95 Successful keyword extraction for at least 90% of fact-check requests\u8232 \'95 Research results displayed within 5 seconds\
Input & Output\uc0\u8232 \'95 Input: Tagged utterance stream (Fact-check request tag), knowledge base or web search API\u8232 \'95 Output: Fact-check result widget with short answer and source link(s)\
Constraints\uc0\u8232 \'95 Max 30 fact-check queries per session\u8232 \'95 Each query result limited to brief, conference-friendly summaries\
C. Post-Presentation Phase\uc0\u8232 This phase involves the user receiving feedback on their presentation and conducting a Q&A session after the presentation has concluded.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls15\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Q&A Auto-Response\uc0\u8232 In Q&A mode, the system uses Retrieval-Augmented Generation (RAG) to search a pre-built database and generate 2\'963 candidate answers, each referencing supporting slides or pages.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 Acceptance Criteria\uc0\u8232 \'95 Answer generation \u8804  5 s\u8232 \'95 Relevance score \u8805  0.85\u8232 \'95 Slide reference accuracy \u8805  98%\
Input & Output\uc0\u8232 \'95 Input: Question (speech/text), presentation DB (JSON)\u8232 \'95 Output: 2\'963 candidate answers with referenced slides\
Constraints\uc0\u8232 \'95 Max 20 questions per session\u8232 \'95 Max 300 tokens per answer\u8232 \'95 RAG cosine similarity \u8805  0.8\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls16\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Presentation and Meeting Analysis Report\uc0\u8232 After the meeting or presentation, the system automatically analyzes collected data (speech logs, agenda map, decisions, action items, and referenced research results) and generates a Meeting Summary Report. This report covers time management, speech habits, content delivery, and meeting outcomes such as major topics, ideas, decisions, action items, and external facts referenced during the discussion.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 Acceptance Criteria\uc0\u8232 \'95 Report generation \u8804  10 s\u8232 \'95 Analysis accuracy \u8805  95%\u8232 \'95 User satisfaction \u8805  4.2/5.0\
Input & Output\uc0\u8232 \'95 Input: Speech logs, slide transitions, emotion data, agenda map, decision/action-item list, fact-check logs\u8232 \'95 Output: Analysis report (.html, .pdf)\
Constraints\uc0\u8232 \'95 Max presentation time: 60 min\u8232 \'95 Max 100,000 words processed\
III. VERSION CONTROL SYSTEM\
To manage source code and documentation, a version control system based on Git was established.\uc0\u8232 A public repository named \'93ai-assistant-for-presentation\'94 was created on GitHub.\
The following source code and documents have been uploaded to the repository:\uc0\u8232 \'95 All backend and frontend source code\u8232 \'95 Shared documents including this file (project_documentation.md) and other design files\u8232 \'95 Configuration files and project-related assets\
All team members (development, project management, and UI/UX design) have been granted access to the repository. For efficient GitHub management, the team will adopt a branch management strategy as illustrated in the diagram below.\
IV. DEVELOPMENT ENVIRONMENT\
A. Choice of Software Development Platform\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls17\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Platform Selection and Rationale\uc0\u8232 The project adopts a web-based client\'96server architecture as its primary development and deployment platform. The web environment ensures platform-independent accessibility without requiring users to install additional software, while providing seamless integration with cloud-based APIs such as Google Cloud Speech-to-Text and large-language-model (LLM) services. Modern web technologies, including WebSockets, Web Audio API, and TensorFlow.js, enable the implementation of essential real-time features such as live teleprompting and synchronized feedback dashboards.\
\ls17\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Programming Languages and Rationale\uc0\u8232 \'95 Backend: Python (version 3.11 or higher) using FastAPI for asynchronous API and WebSocket communication. Python is the de facto standard for AI and machine learning workflows, offering a mature ecosystem that includes python-pptx, sentence-transformers, and google-cloud-speech libraries.\u8232 \'95 Frontend: TypeScript/JavaScript (Node.js 20 or higher) with React 18.2. JavaScript is the only natively supported browser language and is indispensable for client-side interaction. React combined with TypeScript supports modular, maintainable UI components and ensures type safety.\
\ls17\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Cost Estimation\uc0\u8232 The estimated total development cost is approximately USD 30.00, as summarized below:\u8232 \'95 Hardware: Personal laptops (MacBook Air/Pro) \'96 USD 0.00\u8232 \'95 Software and IDE: Visual Studio Code (free), Cursor Pro (USD 20 per month)\u8232 \'95 Cloud Services and APIs: AWS Free Tier, GCP STT and Vision API, OpenAI GPT Realtime Mini (approx. USD 10)\
\ls17\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Development Environment Details\uc0\u8232 \'95 Operating Systems: Windows 11, macOS 14 (Sonoma)\u8232 \'95 IDEs: Visual Studio Code (v1.90 or higher), Cursor (v1.7 or higher)\u8232 \'95 Version Control: Git (v2.39 or higher) and GitHub public repository (\'93ai-assistant-for-presentation\'94)\u8232 \'95 Backend Stack: Python 3.11+, FastAPI 0.110+, PostgreSQL 16 (Render hosted)\u8232 \'95 Frontend Stack: Node.js 20.10+, npm 10.2+, React 18.2+, TypeScript 5.2+\u8232 \'95 Major Libraries: python-pptx, sentence-transformers, websockets, TensorFlow.js, Web Audio API\u8232 \'95 Hardware Resources: Three personal laptops (two MacBook Airs, one MacBook Pro) used for development and testing.\
\ls17\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	5	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Use of Commercial Cloud Platforms\uc0\u8232 \'95 Google Cloud Platform (GCP): Utilized for Speech-to-Text and Vision OCR services to enable high-accuracy transcription and slide text extraction. Services operate within free-tier quotas.\u8232 \'95 Amazon Web Services (AWS): EC2 for backend deployment, S3 for file storage, RDS for database hosting, and Route 53 for domain management. Free-tier services are used for prototype deployment and demonstration.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 B. Software in Use\uc0\u8232 Several existing software solutions and research studies were referenced in designing the system:\u8232 \'95 PromptSmart (VoiceTrack): A commercial teleprompter offering real-time voice tracking. The proposed system extends its capabilities by adding semantic matching, omission detection, and automated slide control.\u8232 \'95 Microsoft PowerPoint (Live Subtitles): Provides speech transcription but lacks contextual synchronization with scripts and automated slide transitions.\
These benchmarks highlight the project\'92s improvements in real-time adaptivity and AI-driven presentation assistance.\
C. Task Distribution\
Role / Members / Responsibilities\
Backend Development\uc0\u8232 Sangyoon Kwon, Dohoon Kim\u8232 System architecture design, FastAPI server and WebSocket implementation, database schema (PostgreSQL), AI logic integration (STT, LLM, BERT), cloud deployment (AWS, Render)\
Frontend Development\uc0\u8232 Hyeyun Kwon, Seohyun Kim\u8232 React-based UI implementation, client-side state management, real-time dashboard (Web Audio API), teleprompter interface, client-side AI (TensorFlow.js)\
Project Management & UI Design\uc0\u8232 Daeun Lee, Minhyuk Jang\u8232 Project planning and scheduling, UI/UX design (Figma), documentation and VCS management, user testing and feedback analysis\
V. SPECIFICATION\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls18\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Requirement 1. Real-Time Teleprompter\uc0\u8232 This process involves a tightly coordinated real-time loop between the client (web browser) and the server (Python backend) through WebSocket communication.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls19\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Client Initialization\uc0\u8232 When the user presses \'93Start Presentation,\'94 the React frontend requests microphone access using navigator.mediaDevices.getUserMedia() and establishes a secure WebSocket (wss://) connection to the backend API server. The Web Audio API initializes an AudioContext and ScriptProcessorNode to capture raw audio chunks.\
\ls19\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Client-Side Real-Time Audio Streaming\uc0\u8232 The ScriptProcessorNode continuously triggers onaudioprocess events (e.g., every 500 ms). Each raw audio buffer (16-bit PCM) is sent to the backend server through WebSocket.\
\ls19\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Server-Side STT and Synchronization\uc0\u8232 The backend receives the audio chunks and streams them to the Google Cloud Speech-to-Text API. The API returns interim (fast but less accurate) and final (slower but more accurate) transcripts. When a final sentence is received, it is appended to the full transcript of the session. The backend then calls the FlexibleSpeechMatcher service to locate the new currentSentenceIndex within the user\'92s script.\
\ls19\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Server Broadcast\uc0\u8232 The server immediately sends a WebSocket message to the client:\u8232 \{ "action": "UPDATE_TELEPROMPTER", "index": currentSentenceIndex \}\
\ls19\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	5	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Client Update\uc0\u8232 The frontend WebSocket listener receives the message and updates the highlighted text accordingly, scrolling the teleprompter to the current index in real time.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls20\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Requirement 2. Flexible Speech-to-Script Matching\uc0\u8232 This algorithm implements a hybrid matching mechanism combining fast vector similarity and fallback large-language-model (LLM) validation.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 Pseudocode Overview\
SIMILARITY_THRESHOLD = 0.75\uc0\u8232 SEARCH_WINDOW = 5\u8232 LLM_VALIDATION_THRESHOLD = 0.60\
Function FindCurrentPosition(fullTranscript, scriptSentences, lastIndex):\uc0\u8232 latestTranscript = GetLastNWords(fullTranscript, 10)\u8232 transcriptVector = KoSentenceBERT.encode(latestTranscript)\u8232 searchStart = lastIndex\u8232 searchEnd = min(lastIndex + SEARCH_WINDOW, len(scriptSentences))\u8232 searchWindow = scriptSentences[searchStart : searchEnd]\u8232 bestMatchIndex = -1\u8232 highestSimilarity = 0\
\pard\pardeftab720\partightenfactor0

\f1\fs26 \cf0 # Step 1: Fast vector similarity  \
for index, sentence in enumerate(searchWindow):  \
    similarity = CosineSimilarity(transcriptVector, sentence.vector)  \
    if similarity > highestSimilarity:  \
        highestSimilarity = similarity  \
        bestMatchIndex = searchStart + index  \
\
# Step 2: Omission check  \
if bestMatchIndex > lastIndex:  \
    CheckForOmissions(lastIndex, bestMatchIndex, scriptSentences)  \
\
if highestSimilarity >= SIMILARITY_THRESHOLD:  \
    return bestMatchIndex  \
\
# Step 3: LLM fallback validation  \
if highestSimilarity >= LLM_VALIDATION_THRESHOLD:  \
    prompt = CreateLLMPrompt(latestTranscript, searchWindow)  \
    AsyncCallLLM(prompt, HandleLLMResult)  \
    return bestMatchIndex  \
\
return lastIndex  \
\pard\pardeftab720\sa240\partightenfactor0

\f0\fs24 \cf0 This process ensures low latency while maintaining semantic accuracy through adaptive matching.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls21\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Requirement 3. Key Content Omission Detection\uc0\u8232 This function integrates directly with the flexible matching process. When a skipped section is detected, the system checks whether any omitted sentence contains a predefined key phrase and alerts the presenter.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls22\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Database Preparation\uc0\u8232 When users upload a script, each sentence is marked with a boolean attribute isKeyPhrase (true / false) and stored in the database.\
\ls22\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Server-Side Omission Detection\uc0\u8232 When FindCurrentPosition() identifies a new bestMatchIndex greater than lastIndex + 1, the server calls CheckForOmissions().\
\ls22\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Omission Logic\uc0\u8232 If skipped sentences are found between the two indices, each is inspected for isKeyPhrase == true. When detected, the omitted sentence index is flagged, and the following message is broadcast:\u8232 \{ "action": "OMISSION_DETECTED", "index": omittedSentenceIndex \}\
\ls22\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Client Notification\uc0\u8232 The frontend highlights the corresponding part of the script (e.g., flashing red or adding a border) to visually warn the presenter in real time. Simultaneously, an asynchronous script-reconstruction task (Requirement 4) is triggered.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls23\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Requirement 4. Real-Time Script Reconstruction\uc0\u8232 This asynchronous process generates short \'93bridging sentences\'94 whenever key content omissions are detected, ensuring smooth narrative flow without latency in the main loop.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls24\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Asynchronous Trigger\uc0\u8232 CheckForOmissions() launches HandleOmissionAsynchronously() in a separate asynchronous task.\
\ls24\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Prompt Generation for LLM\uc0\u8232 The function combines three inputs:\u8232 (a) the omitted sentence, (b) the current context sentences, and (c) an instruction prompt such as:\u8232 \'93You are a presentation coach. The presenter accidentally omitted '[omittedSentence]' and is now moving to '[contextSentences]'. Please generate one short, natural bridging sentence in Korean that connects these topics smoothly.\'94\
\ls24\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 LLM API Invocation\uc0\u8232 The backend asynchronously requests an LLM (e.g., GPT or Gemini) to generate the bridging sentence.\
\ls24\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Response Delivery\uc0\u8232 Upon success, the server sends the message:\u8232 \{ "action": "SCRIPT_SUGGESTION", "text": llm_generated_sentence \}\
\ls24\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	5	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Client Interface Behavior\uc0\u8232 The React frontend displays the generated sentence in the AI Suggestion section as an alert message: \'93Do you approve this suggestion?\'94 with Accept (#0064FF) and No (#E0E6EA) buttons. If the user selects Accept, the updated script is applied, and a small alert \'93Update complete\'94 appears at the top-right corner.\
}